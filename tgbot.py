import logging
import os
from g4f.client import Client
import g4f
import requests
from telegram import Update, ParseMode, InlineKeyboardButton, InlineKeyboardMarkup, ReplyKeyboardMarkup, KeyboardButton
from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, CallbackContext, CallbackQueryHandler, ConversationHandler
from PIL import Image
from io import BytesIO
import tempfile
import re

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO
)
logger = logging.getLogger(__name__)

# –¢–æ–∫–µ–Ω Telegram –±–æ—Ç–∞
TOKEN = ""

# –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ Telegram
MAX_MESSAGE_LENGTH = 4000  # –û—Å—Ç–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à–æ–π –∑–∞–ø–∞—Å –æ—Ç –ª–∏–º–∏—Ç–∞ –≤ 4096

# –°–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è ConversationHandler
WAITING_FOR_GPT_PROMPT = 1
WAITING_FOR_IMAGE_PROMPT = 2

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è g4f –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
g4f.debug.logging = False  # –û—Ç–∫–ª—é—á–∏—Ç—å –¥–µ–±–∞–≥ –ª–æ–≥–∏
# –ü–æ–ª—É—á–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏
try:
    # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –º–æ–¥–µ–ª–∏ –∏–∑ –Ω–æ–≤–æ–≥–æ API
    available_models = list(g4f.models.__all__)
except:
    try:
        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–± –¥–ª—è –Ω–æ–≤—ã—Ö –≤–µ—Ä—Å–∏–π
        available_models = [model.__name__ for model in g4f.models.list()]
    except:
        # –ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
        available_models = ["gpt-3.5-turbo", "gpt-4", "gpt-4o", "gpt-4o-mini"]

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–æ–¥–µ–ª–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
try:
    # –ú–æ–¥–µ–ª—å –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
    if hasattr(g4f.models, "gpt_4o_mini"):
        text_model = g4f.models.gpt_4o_mini
    else:
        text_model = "gpt-4o-mini"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç—Ä–æ–∫–æ–≤–æ–µ –∏–º—è –º–æ–¥–µ–ª–∏
    
    # –ú–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    if hasattr(g4f.models, "flux"):
        image_model = g4f.models.flux
    else:
        image_model = "flux"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç—Ä–æ–∫–æ–≤–æ–µ –∏–º—è –º–æ–¥–µ–ª–∏
except:
    text_model = "gpt-4o-mini"
    image_model = "flux"

# –ò—Å—Ç–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
user_history = {}

def start(update: Update, context: CallbackContext) -> None:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start"""
    user = update.effective_user
    user_id = update.effective_user.id
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –±–µ–∑ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –æ —Ä–∞–∑–º–µ—Ç–∫–µ
    user_history[user_id] = []
    
    # –°–æ–∑–¥–∞–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å –æ—Å–Ω–æ–≤–Ω—ã–º–∏ –∫–æ–º–∞–Ω–¥–∞–º–∏
    keyboard = [
        [KeyboardButton("ü§ñ GPT"), KeyboardButton("üñº –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")]
    ]
    reply_markup = ReplyKeyboardMarkup(keyboard, resize_keyboard=True)
    
    update.message.reply_text(
        f'–ü—Ä–∏–≤–µ—Ç, {user.first_name}! –Ø –±–æ—Ç, —Ä–∞–±–æ—Ç–∞—é—â–∏–π —Å GPT. '
        f'–í—ã –º–æ–∂–µ—Ç–µ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –º–Ω–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –∏ —è –æ—Ç–≤–µ—á—É, –∏—Å–ø–æ–ª—å–∑—É—è GPT4free.\n\n'
        f'–¢–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:\n'
        f'- –¢–µ–∫—Å—Ç–æ–≤—ã–µ –æ—Ç–≤–µ—Ç—ã: gpt-4o-mini\n'
        f'- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: flux\n\n'
        f'–ö–æ–º–∞–Ω–¥—ã:\n'
        f'/gpt <—Å–æ–æ–±—â–µ–Ω–∏–µ> - –ü–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç GPT\n'
        f'/image <–æ–ø–∏—Å–∞–Ω–∏–µ> - –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ',
        reply_markup=reply_markup
    )

def get_gpt_response(prompt, model=text_model, history=None):
    """–ü–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç GPT4free"""
    try:
        messages = []
        if history:
            messages.extend(history)
        
        messages.append({"role": "user", "content": prompt})
        
        try:
            # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–ª–∏–µ–Ω—Ç API
            client = Client()
            response = client.chat.completions.create(
                model=model,
                messages=messages,
            )
            response_text = response.choices[0].message.content
        except Exception as client_error:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞: {client_error}")
            # –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥
            response_text = g4f.ChatCompletion.create(
                model=model,
                messages=messages,
                stream=False,
            )
        
        return response_text, {"role": "assistant", "content": response_text}
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç GPT: {e}")
        return f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}", None

def generate_image(prompt):
    """–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é"""
    try:
        # –õ–æ–≥–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å
        logger.info(f"–ó–∞–ø—Ä–æ—Å –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {prompt}")
        
        # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç
        client = Client()
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        response = client.images.generate(
            model="flux",
            prompt=prompt,
            response_format="url"
        )
        
        # –ü–æ–ª—É—á–∞–µ–º URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if response and hasattr(response, 'data') and len(response.data) > 0:
            image_url = response.data[0].url
            logger.info(f"–ü–æ–ª—É—á–µ–Ω URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image_url}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            img_response = requests.get(image_url, timeout=60)
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            return img_response.content
        
        return None
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        return None

def handle_message(update: Update, context: CallbackContext) -> None:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ–±—ã—á–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
    user_id = update.effective_user.id
    prompt = update.message.text
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–Ω–æ–ø–æ–∫ –º–µ–Ω—é
    if prompt == "ü§ñ GPT":
        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤–≤–æ–¥ –¥–ª—è GPT
        update.message.reply_text(
            "–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å –¥–ª—è GPT:",
            reply_markup=InlineKeyboardMarkup([
                [InlineKeyboardButton("–û—Ç–º–µ–Ω–∞", callback_data="cancel")]
            ])
        )
        return WAITING_FOR_GPT_PROMPT
    
    elif prompt == "üñº –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ":
        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        update.message.reply_text(
            "–í–≤–µ–¥–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä–æ–µ —Ö–æ—Ç–∏—Ç–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å:",
            reply_markup=InlineKeyboardMarkup([
                [InlineKeyboardButton("–û—Ç–º–µ–Ω–∞", callback_data="cancel")]
            ])
        )
        return WAITING_FOR_IMAGE_PROMPT
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    if user_id not in user_history:
        user_history[user_id] = []
    
    # –û—Ç–ø—Ä–∞–≤–∫–∞ "–ø–µ—á–∞—Ç–∞–µ—Ç..."
    context.bot.send_chat_action(chat_id=update.effective_chat.id, action='typing')
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç GPT
    response, assistant_message = get_gpt_response(prompt, history=user_history[user_id])
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –∏—Å—Ç–æ—Ä–∏—é
    user_history[user_id].append({"role": "user", "content": prompt})
    if assistant_message:
        user_history[user_id].append(assistant_message)
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –¥–ª–∏–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–∞ —á–∞—Å—Ç–∏ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º
    message_parts = split_long_message(response)
    for i, part in enumerate(message_parts):
        try:
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä —á–∞—Å—Ç–∏ –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
            if len(message_parts) > 1:
                part_indicator = f"[–ß–∞—Å—Ç—å {i+1}/{len(message_parts)}]\n"
                if i > 0:  # –î–ª—è –≤—Å–µ—Ö —á–∞—Å—Ç–µ–π, –∫—Ä–æ–º–µ –ø–µ—Ä–≤–æ–π, –¥–æ–±–∞–≤–ª—è–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –≤ –Ω–∞—á–∞–ª–æ
                    part = part_indicator + part
                else:  # –î–ª—è –ø–µ—Ä–≤–æ–π —á–∞—Å—Ç–∏ –¥–æ–±–∞–≤–ª—è–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω –ø–æ–º–µ—Å—Ç–∏—Ç—Å—è
                    if len(part) + len(part_indicator) <= MAX_MESSAGE_LENGTH:
                        part = part_indicator + part
            
            update.message.reply_text(part, parse_mode=ParseMode.MARKDOWN)
        except Exception as e:
            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å Markdown, –ø—Ä–æ–±—É–µ–º –±–µ–∑ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Å Markdown: {e}")
            update.message.reply_text(part)
    
    return ConversationHandler.END

def handle_gpt_prompt(update: Update, context: CallbackContext) -> int:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤–≤–æ–¥–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è GPT –ø–æ—Å–ª–µ –Ω–∞–∂–∞—Ç–∏—è –∫–Ω–æ–ø–∫–∏ GPT"""
    user_id = update.effective_user.id
    prompt = update.message.text
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    if user_id not in user_history:
        user_history[user_id] = []
    
    # –û—Ç–ø—Ä–∞–≤–∫–∞ "–ø–µ—á–∞—Ç–∞–µ—Ç..."
    context.bot.send_chat_action(chat_id=update.effective_chat.id, action='typing')
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç GPT
    response, assistant_message = get_gpt_response(prompt, history=user_history[user_id])
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –∏—Å—Ç–æ—Ä–∏—é
    user_history[user_id].append({"role": "user", "content": prompt})
    if assistant_message:
        user_history[user_id].append(assistant_message)
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –¥–ª–∏–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–∞ —á–∞—Å—Ç–∏ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º
    message_parts = split_long_message(response)
    for i, part in enumerate(message_parts):
        try:
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä —á–∞—Å—Ç–∏ –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
            if len(message_parts) > 1:
                part_indicator = f"[–ß–∞—Å—Ç—å {i+1}/{len(message_parts)}]\n"
                if i > 0:  # –î–ª—è –≤—Å–µ—Ö —á–∞—Å—Ç–µ–π, –∫—Ä–æ–º–µ –ø–µ—Ä–≤–æ–π, –¥–æ–±–∞–≤–ª—è–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –≤ –Ω–∞—á–∞–ª–æ
                    part = part_indicator + part
                else:  # –î–ª—è –ø–µ—Ä–≤–æ–π —á–∞—Å—Ç–∏ –¥–æ–±–∞–≤–ª—è–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω –ø–æ–º–µ—Å—Ç–∏—Ç—Å—è
                    if len(part) + len(part_indicator) <= MAX_MESSAGE_LENGTH:
                        part = part_indicator + part
            
            update.message.reply_text(part, parse_mode=ParseMode.MARKDOWN)
        except Exception as e:
            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å Markdown, –ø—Ä–æ–±—É–µ–º –±–µ–∑ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Å Markdown: {e}")
            update.message.reply_text(part)
    
    return ConversationHandler.END

def handle_image_prompt(update: Update, context: CallbackContext) -> int:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤–≤–æ–¥–∞ –æ–ø–∏—Å–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ—Å–ª–µ –Ω–∞–∂–∞—Ç–∏—è –∫–Ω–æ–ø–∫–∏ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"""
    prompt = update.message.text
    
    # –û—Ç–ø—Ä–∞–≤–∫–∞ "–æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ñ–æ—Ç–æ..."
    context.bot.send_chat_action(chat_id=update.effective_chat.id, action='upload_photo')
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    img_data = generate_image(prompt)
    
    if img_data:
        # –û—Ç–ø—Ä–∞–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp_file:
            tmp_file.write(img_data)
            tmp_file_path = tmp_file.name
        
        with open(tmp_file_path, 'rb') as f:
            update.message.reply_photo(
                photo=f, 
                caption=f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –ø–æ –∑–∞–ø—Ä–æ—Å—É: {prompt}"
            )
        
        # –£–¥–∞–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        os.unlink(tmp_file_path)
        
        # –£–±–∏—Ä–∞–µ–º –æ—á–∏—Å—Ç–∫—É –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ—Å–ª–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        # user_id = update.effective_user.id
        # if user_id in user_history:
        #     user_history[user_id] = []
    else:
        update.message.reply_text('–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π –∑–∞–ø—Ä–æ—Å.')
    
    return ConversationHandler.END

def cancel(update: Update, context: CallbackContext) -> int:
    """–û—Ç–º–µ–Ω–∞ —Ç–µ–∫—É—â–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞"""
    query = update.callback_query
    query.answer()
    query.edit_message_text(text="–û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞.")
    return ConversationHandler.END

def handle_gpt_command(update: Update, context: CallbackContext) -> None:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /gpt"""
    user_id = update.effective_user.id
    
    if not context.args:
        update.message.reply_text('–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –¥–æ–±–∞–≤—å—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã /gpt')
        return
    
    prompt = ' '.join(context.args)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    if user_id not in user_history:
        user_history[user_id] = []
    
    # –û—Ç–ø—Ä–∞–≤–∫–∞ "–ø–µ—á–∞—Ç–∞–µ—Ç..."
    context.bot.send_chat_action(chat_id=update.effective_chat.id, action='typing')
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç GPT
    response, assistant_message = get_gpt_response(prompt, history=user_history[user_id])
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –∏—Å—Ç–æ—Ä–∏—é
    user_history[user_id].append({"role": "user", "content": prompt})
    if assistant_message:
        user_history[user_id].append(assistant_message)
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –¥–ª–∏–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–∞ —á–∞—Å—Ç–∏ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º
    message_parts = split_long_message(response)
    for i, part in enumerate(message_parts):
        try:
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä —á–∞—Å—Ç–∏ –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
            if len(message_parts) > 1:
                part_indicator = f"[–ß–∞—Å—Ç—å {i+1}/{len(message_parts)}]\n"
                if i > 0:  # –î–ª—è –≤—Å–µ—Ö —á–∞—Å—Ç–µ–π, –∫—Ä–æ–º–µ –ø–µ—Ä–≤–æ–π, –¥–æ–±–∞–≤–ª—è–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –≤ –Ω–∞—á–∞–ª–æ
                    part = part_indicator + part
                else:  # –î–ª—è –ø–µ—Ä–≤–æ–π —á–∞—Å—Ç–∏ –¥–æ–±–∞–≤–ª—è–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω –ø–æ–º–µ—Å—Ç–∏—Ç—Å—è
                    if len(part) + len(part_indicator) <= MAX_MESSAGE_LENGTH:
                        part = part_indicator + part
            
            update.message.reply_text(part, parse_mode=ParseMode.MARKDOWN)
        except Exception as e:
            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å Markdown, –ø—Ä–æ–±—É–µ–º –±–µ–∑ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Å Markdown: {e}")
            update.message.reply_text(part)

def handle_image_command(update: Update, context: CallbackContext) -> None:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /image"""
    if not context.args:
        update.message.reply_text('–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –¥–æ–±–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã /image')
        return
    
    prompt = ' '.join(context.args)
    
    # –û—Ç–ø—Ä–∞–≤–∫–∞ "–æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ñ–æ—Ç–æ..."
    context.bot.send_chat_action(chat_id=update.effective_chat.id, action='upload_photo')
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    img_data = generate_image(prompt)
    
    if img_data:
        # –û—Ç–ø—Ä–∞–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp_file:
            tmp_file.write(img_data)
            tmp_file_path = tmp_file.name
        
        with open(tmp_file_path, 'rb') as f:
            update.message.reply_photo(
                photo=f, 
                caption=f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –ø–æ –∑–∞–ø—Ä–æ—Å—É: {prompt}"
            )
        
        # –£–¥–∞–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        os.unlink(tmp_file_path)
        
        # –£–±–∏—Ä–∞–µ–º –æ—á–∏—Å—Ç–∫—É –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ—Å–ª–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        # user_id = update.effective_user.id
        # if user_id in user_history:
        #     user_history[user_id] = []
    else:
        update.message.reply_text('–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π –∑–∞–ø—Ä–æ—Å.')

def clear_history(update: Update, context: CallbackContext) -> None:
    """–û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    user_id = update.effective_user.id
    if user_id in user_history:
        user_history[user_id] = []
    update.message.reply_text('–ò—Å—Ç–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π –æ—á–∏—â–µ–Ω–∞.')

def list_models(update: Update, context: CallbackContext) -> None:
    """–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    models_list = "\n".join(available_models)
    update.message.reply_text(f'–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:\n{models_list}')

def split_long_message(text, max_length=MAX_MESSAGE_LENGTH):
    """–†–∞–∑–±–∏–≤–∞–µ—Ç –¥–ª–∏–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–∞ —á–∞—Å—Ç–∏ –ø–æ–¥—Ö–æ–¥—è—â–µ–π –¥–ª–∏–Ω—ã"""
    if len(text) <= max_length:
        return [text]
    
    parts = []
    while text:
        # –ù–∞—Ö–æ–¥–∏–º –ø–æ–¥—Ö–æ–¥—è—â–µ–µ –º–µ—Å—Ç–æ –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è (–ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–æ –Ω–∞ –ø–µ—Ä–µ–Ω–æ—Å–µ —Å—Ç—Ä–æ–∫–∏ –∏–ª–∏ –ø—Ä–æ–±–µ–ª–µ)
        if len(text) <= max_length:
            parts.append(text)
            break
        
        # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö max_length
        split_point = text[:max_length].rfind('\n')
        if split_point == -1 or split_point < max_length // 2:
            # –ï—Å–ª–∏ –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –±–ª–∏–∑–∫–æ –∫ –Ω–∞—á–∞–ª—É,
            # –∏—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø—Ä–æ–±–µ–ª
            split_point = text[:max_length].rfind(' ')
            if split_point == -1 or split_point < max_length // 2:
                # –ï—Å–ª–∏ –∏ –ø—Ä–æ–±–µ–ª –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ—Å—Ç–æ —Ä–∞–∑–¥–µ–ª—è–µ–º –ø–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω–µ
                split_point = max_length
        else:
            # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏, –≤–∫–ª—é—á–∞–µ–º –µ–≥–æ –≤ —Ç–µ–∫—É—â—É—é —á–∞—Å—Ç—å
            split_point += 1
        
        parts.append(text[:split_point])
        text = text[split_point:]
    
    return parts

def main() -> None:
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –±–æ—Ç–∞"""
    # –°–æ–∑–¥–∞–Ω–∏–µ Updater –∏ –ø–µ—Ä–µ–¥–∞—á–∞ —Ç–æ–∫–µ–Ω–∞ –±–æ—Ç–∞
    updater = Updater(TOKEN)

    # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∏—Å–ø–µ—Ç—á–µ—Ä–∞ –¥–ª—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤
    dispatcher = updater.dispatcher

    # –°–æ–∑–¥–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –¥–ª—è –∫–Ω–æ–ø–æ–∫ –º–µ–Ω—é
    conv_handler = ConversationHandler(
        entry_points=[MessageHandler(Filters.text & ~Filters.command, handle_message)],
        states={
            WAITING_FOR_GPT_PROMPT: [MessageHandler(Filters.text & ~Filters.command, handle_gpt_prompt)],
            WAITING_FOR_IMAGE_PROMPT: [MessageHandler(Filters.text & ~Filters.command, handle_image_prompt)],
        },
        fallbacks=[CallbackQueryHandler(cancel, pattern='^cancel$')],
    )
    
    # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ –∫–æ–º–∞–Ω–¥
    dispatcher.add_handler(CommandHandler("start", start))
    dispatcher.add_handler(CommandHandler("gpt", handle_gpt_command))
    dispatcher.add_handler(CommandHandler("image", handle_image_command))
    
    # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
    dispatcher.add_handler(conv_handler)
    
    # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ callback-–∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –∫–Ω–æ–ø–æ–∫
    dispatcher.add_handler(CallbackQueryHandler(cancel))

    # –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
    updater.start_polling()
    updater.idle()

if __name__ == '__main__':
    main()
